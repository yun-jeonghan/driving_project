import sys
import os
import torch
import numpy as np
import cv2
from pathlib import Path

# 1. ê²½ë¡œ ì„¤ì •
CORE_DIR = Path(__file__).resolve().parent
BASE_DIR = CORE_DIR.parents[1] 
REPO_PATH = BASE_DIR / "FastVGGT_repo"
MODELS_DIR = BASE_DIR / "models"

if str(REPO_PATH) not in sys.path:
    sys.path.insert(0, str(REPO_PATH))

# 2. [í•µì‹¬] ëŸ°íƒ€ì„ ëª½í‚¤ íŒ¨ì¹˜ (ì›ë³¸ íŒŒì¼ ìˆ˜ì • X)
try:
    import merging.merge as vggt_merge
    original_func = vggt_merge.fast_similarity_chunks

    def patched_fast_similarity_chunks(a, b, chunk_size, *args, **kwargs):
        # chunk_sizeê°€ 0ì´ê±°ë‚˜ ë„ˆë¬´ ì‘ìœ¼ë©´ ê°•ì œë¡œ 1024ë¡œ í• ë‹¹
        safe_chunk_size = chunk_size if (chunk_size and chunk_size > 0) else 1024
        return original_func(a, b, safe_chunk_size, *args, **kwargs)

    # ë©”ëª¨ë¦¬ìƒì—ì„œ í•¨ìˆ˜ êµì²´
    vggt_merge.fast_similarity_chunks = patched_fast_similarity_chunks
    print("âœ… FastVGGT ëŸ°íƒ€ì„ íŒ¨ì¹˜ ì ìš© ì™„ë£Œ (ì›ë³¸ ë³´ì¡´)")
except Exception as e:
    print(f"âš ï¸ íŒ¨ì¹˜ ì ìš© ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

try:
    from vggt.models.vggt import VGGT
except ImportError:
    print("âŒ ë ˆí¬ì§€í† ë¦¬ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

class DrivingAnalyzer:
    def __init__(self, yolo_path, vggt_path):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        from ultralytics import YOLO
        
        self.detector = YOLO(str(yolo_path))
        self.vggt = VGGT()
        
        checkpoint = torch.load(str(vggt_path), map_location=self.device)
        state_dict = checkpoint.get('model', checkpoint.get('state_dict', checkpoint))
        self.vggt.load_state_dict(state_dict, strict=False)
        self.vggt.to(self.device).eval()

        self.history = {}  # {object_id: {'dist': d, 'time': t}} í˜•íƒœ ì €ì¥
        print("âœ… ëª¨ë¸ ë¡œë“œ ë° ì¥ì¹˜ í• ë‹¹ ì™„ë£Œ")

    @torch.no_grad()
    def _get_depth_map(self, frame):
        # 1. ì „ì²˜ë¦¬ (Dust3r/FastVGGT ìµœì í™” í•´ìƒë„)
        target_w, target_h = 518, 392
        img_input = cv2.resize(frame, (target_w, target_h))
        img_tensor = torch.from_numpy(img_input).permute(2, 0, 1).float().to(self.device) / 255.0
        img_tensor = img_tensor.unsqueeze(0)
        
        # 2. ì¶”ë¡ 
        with torch.cuda.amp.autocast(enabled=True, dtype=torch.bfloat16):
            output = self.vggt(img_tensor)
        
        # 3. [ì—ëŸ¬ í•´ê²° ì§€ì ] ê²°ê³¼ íŒŒì‹± (or ì—°ì‚°ì ì œê±°)
        if isinstance(output, dict):
            # 'depth' í‚¤ê°€ ìˆìœ¼ë©´ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë°¸ë¥˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            depth = output.get('depth')
            if depth is None:
                depth = list(output.values())[0]
        elif isinstance(output, (list, tuple)):
            # ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜ë  ê²½ìš° ì²« ë²ˆì§¸ ì•„ì´í…œ ì„ íƒ
            depth = output[0]
        else:
            depth = output
            
        # 4. í›„ì²˜ë¦¬: í…ì„œë¼ë©´ numpyë¡œ ë³€í™˜
        if torch.is_tensor(depth):
            return depth.squeeze().float().cpu().numpy()
        return depth # ì´ë¯¸ numpyì¸ ê²½ìš°

    def analyze(self, frame):
        yolo_res = self.detector(frame, verbose=False)[0]
        depth_map = self._get_depth_map(frame)
        depth_map_resized = cv2.resize(depth_map, (frame.shape[1], frame.shape[0]))

        results = []
        for box in yolo_res.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            label = self.detector.names[int(box.cls[0])]
            
            roi_depth = depth_map_resized[y1:y2, x1:x2]
            avg_depth = np.mean(roi_depth) if roi_depth.size > 0 else 50.0
            
            # ìœ„í—˜ë„ ê³„ì‚°: ê¸°ì¤€ ê±°ë¦¬ 10m
            risk = round(10.0 / (avg_depth + 1e-6), 4)
            
            # ê²½ë³´ ë“±ê¸‰
            alert = "NORMAL"
            if risk >= 1.5: alert = "DANGER"
            elif risk >= 0.8: alert = "WARNING"
            
            results.append({
                "label": label, "dist_m": round(float(avg_depth), 2),
                "risk": risk, "alert": alert, "bbox": [x1, y1, x2, y2]
            })
        return results

    def draw_results(self, frame, results):
        """ë¶„ì„ ê²°ê³¼(BBox, ID, ê±°ë¦¬, ì†ë„, ë¦¬ìŠ¤í¬)ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦½ë‹ˆë‹¤."""
        annotated_frame = frame.copy()
        
        for res in results:
            # ì¢Œí‘œ ë° ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            x1, y1, x2, y2 = res['bbox']
            obj_id = res.get('id', '?')
            label = res['label']
            dist = res['dist_m']
            velocity = res.get('velocity_mps', 0.0) # ì†ë„ ì •ë³´ê°€ ì—†ìœ¼ë©´ 0 ì²˜ë¦¬
            risk = res['risk']
            alert = res['alert']
            
            # ê²½ë³´ ë ˆë²¨ì— ë”°ë¥¸ ìƒ‰ìƒ ì„¤ì • (BGR)
            color = (0, 255, 0) # Green (Normal)
            thickness = 2
            if alert == "DANGER": 
                color = (0, 0, 255) # Red
                thickness = 3
            elif alert == "WARNING": 
                color = (0, 165, 255) # Orange
            
            # 1. ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, thickness)
            
            # 2. í…ìŠ¤íŠ¸ ì •ë³´ êµ¬ì„± (ID, ë¼ë²¨, ê±°ë¦¬, ì†ë„)
            # ì˜ˆ: [ID:1] car | 12.5m | -3.2m/s (ë©€ì–´ì§)
            vel_str = f"{velocity:+.1f}m/s" if velocity != 0 else "Stable"
            label_text = f"[ID:{obj_id}] {label} | {dist}m | {vel_str}"
            
            # 3. ë¦¬ìŠ¤í¬ ì ìˆ˜ í…ìŠ¤íŠ¸
            risk_text = f"Risk: {risk} ({alert})"
            
            # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ê°€ë…ì„± í™•ë³´)
            (tw1, th1), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
            (tw2, th2), _ = cv2.getTextSize(risk_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
            cv2.rectangle(annotated_frame, (x1, y1 - th1 - th2 - 15), (x1 + max(tw1, tw2), y1), color, -1)
            
            # í…ìŠ¤íŠ¸ ì“°ê¸° (í°ìƒ‰ ê¸€ì”¨)
            cv2.putText(annotated_frame, label_text, (x1, y1 - th1 - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            cv2.putText(annotated_frame, risk_text, (x1, y1 - 5), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return annotated_frame
    
    def calculate_velocity(self, obj_id, current_dist, current_time):
        """ì´ì „ ê¸°ë¡ê³¼ ë¹„êµí•˜ì—¬ ìƒëŒ€ ì†ë„(m/s) ê³„ì‚°"""
        if obj_id not in self.history:
            self.history[obj_id] = {'dist': current_dist, 'time': current_time}
            return 0.0
        
        prev = self.history[obj_id]
        delta_d = prev['dist'] - current_dist  # ì–‘ìˆ˜ë©´ ê°€ê¹Œì›Œì§€ëŠ” ì¤‘
        delta_t = current_time - prev['time']
        
        velocity = delta_d / delta_t if delta_t > 0 else 0
        
        # ê¸°ë¡ ì—…ë°ì´íŠ¸
        self.history[obj_id] = {'dist': current_dist, 'time': current_time}
        return velocity
    
    def analyze_video_frame(self, frame, timestamp):
        # 1. ì¼ë‹¨ íƒì§€(Detection)ë¥¼ ë¨¼ì € ìˆ˜í–‰í•©ë‹ˆë‹¤. (íŠ¸ë˜í‚¹ì—ë§Œ ì˜ì¡´ X)
        results = self.detector.track(frame, persist=True, verbose=False)[0]
        
        depth_map = self._get_depth_map(frame)
        depth_map_resized = cv2.resize(depth_map, (frame.shape[1], frame.shape[0]))
        frame_report = []

        if results.boxes is not None:
            boxes = results.boxes.xyxy.cpu().numpy()
            clss = results.boxes.cls.cpu().numpy().astype(int)
            # YOLOê°€ ì¤€ IDê°€ ìˆìœ¼ë©´ ì“°ê³ , ì—†ìœ¼ë©´ -1ë¡œ ë‘¡ë‹ˆë‹¤.
            ids = results.boxes.id.cpu().numpy().astype(int) if results.boxes.id is not None else [-1] * len(boxes)

            for i, (box, obj_id, cls) in enumerate(zip(boxes, ids, clss)):
                x1, y1, x2, y2 = map(int, box)
                label = self.detector.names[cls]
                center_now = ((x1 + x2) / 2, (y1 + y2) / 2)

                # [í•µì‹¬] 1ì´ˆ ê°„ê²© ëŒ€ì‘ ê°•ì œ ë§¤ì¹­ ë¡œì§
                # YOLOê°€ IDë¥¼ ëª» ì¤¬ê±°ë‚˜(-1), ìƒˆë¡œ ë¶€ì—¬í–ˆë”ë¼ë„ ìš°ë¦¬ê°€ íˆìŠ¤í† ë¦¬ì™€ ëŒ€ì¡°í•©ë‹ˆë‹¤.
                best_match_id = obj_id
                min_dist = 200 # 1ì´ˆ ë™ì•ˆ ì´ë™ ê°€ëŠ¥í•œ í”½ì…€ ê±°ë¦¬ (í™”ë©´ í¬ê¸°ì— ë”°ë¼ ì¡°ì ˆ)

                for old_id, old_data in self.history.items():
                    if old_data['label'] == label:
                        # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
                        dist = np.linalg.norm(np.array(center_now) - np.array(old_data['center']))
                        if dist < min_dist:
                            min_dist = dist
                            best_match_id = old_id
                
                # ìµœì¢… ê²°ì •ëœ ID (ìƒˆë¡œ ë‚˜íƒ€ë‚œ ë†ˆì´ë©´ ìƒˆë¡œìš´ ê³ ìœ  ID ë¶€ì—¬)
                if best_match_id == -1:
                    # íˆìŠ¤í† ë¦¬ì— ì—†ëŠ” ì™„ì „íˆ ìƒˆë¡œìš´ ê°ì²´ë¼ë©´ í˜„ì¬ ë£¨í”„ì—ì„œ ê°€ì¥ í° ID + 1 ë¶€ì—¬
                    new_id = max(self.history.keys()) + 1 if self.history else 1
                    obj_id = new_id
                else:
                    obj_id = best_match_id

                # ê±°ë¦¬ ë° ì†ë„ ê³„ì‚°
                roi_depth = depth_map_resized[y1:y2, x1:x2]
                curr_dist = np.mean(roi_depth) if roi_depth.size > 0 else 50.0

                velocity = 0.0
                if obj_id in self.history:
                    prev_data = self.history[obj_id]
                    delta_d = prev_data['dist'] - curr_dist
                    delta_t = timestamp - prev_data['time']
                    if delta_t > 0:
                        velocity = delta_d / delta_t
                
                # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (ë‹¤ìŒ í”„ë ˆì„ì„ ìœ„í•´ ì €ì¥)
                self.history[obj_id] = {
                    'dist': curr_dist, 
                    'time': timestamp, 
                    'center': center_now,
                    'label': label
                }

                # ë¦¬ìŠ¤í¬ ì ìˆ˜ (ì†ë„ê°€ ìŒìˆ˜ë©´ ë©€ì–´ì§€ëŠ” ê²ƒì´ë¯€ë¡œ 0 ì²˜ë¦¬)
                risk = round((10.0 / (curr_dist + 1e-6)) + (max(0, velocity) * 0.7), 4)
                alert = "DANGER" if risk >= 20.0 else "WARNING" if risk >= 10.0 else "NORMAL"

                frame_report.append({
                    "id": int(obj_id),
                    "label": label,
                    "dist_m": round(float(curr_dist), 2),
                    "velocity_mps": round(float(velocity), 2),
                    "risk": risk,
                    "alert": alert,
                    "bbox": [x1, y1, x2, y2]
                })

        return frame_report

if __name__ == "__main__":
    yolo_file = MODELS_DIR / "yolo26n.pt"
    vggt_file = MODELS_DIR / "model_tracker_fixed_e20.pt"

    try:
        analyzer = DrivingAnalyzer(yolo_file, vggt_file)
        
        # í…ŒìŠ¤íŠ¸: ì¸í„°ë„·ì—ì„œ ì‹¤ì œ ë„ë¡œ/ì°¨ëŸ‰ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        import requests
        from PIL import Image
        from io import BytesIO
        
        url = "https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/assets/bus.jpg"
        response = requests.get(url)
        test_img = np.array(Image.open(BytesIO(response.content)))
        test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR) # OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        print("ğŸ“¸ ì‹¤ì œ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘...")
        res = analyzer.analyze(test_img)
        
        if not res:
            print("ğŸ¤” ê°ì²´ê°€ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            print("ğŸš€ [ë¶„ì„ ì„±ê³µ] ê²°ê³¼:")
            for obj in res:
                print(f" - {obj['label']}: ê±°ë¦¬ {obj['dist_m']}m | ìœ„í—˜ë„ {obj['risk']} | ë“±ê¸‰ [{obj['alert']}]")
                
    except Exception as e:
        import traceback
        print(f"âŒ ìµœì¢… ì—ëŸ¬ ìƒì„¸:\n{traceback.format_exc()}")